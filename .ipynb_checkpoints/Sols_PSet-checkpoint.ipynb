{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBEeD6O1pWrj"
   },
   "source": [
    "### Challenges\n",
    "\n",
    "The challenges are designed to gain level with each subsequent challenge so we'll recommend doing them in order, also some are interlinked to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BwGOIzvvqPkJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccab9iPkpWrk"
   },
   "source": [
    "Q1.\n",
    "There's a data folder present in the same directory as this file if you performed the instructions carefully. There should be a csv, tsv and excel file in there. Try importing those and store them in air_csv, df_tsv & df_excel respectively.\n",
    "\n",
    "You might face an issue with reading the csv file (yeah we can see into the future xD) so we suggest reading the docs here (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html) to look for encoding parameter then look here ( https://docs.python.org/3/library/codecs.html#standard-encodings) and see the different types of encoding python offers and finally use 'cp1252' encoding to fix the error\n",
    "\n",
    "Also you can do a simple google search and lo behold SO came to our rescue\n",
    "https://stackoverflow.com/questions/45529507/unicodedecodeerror-utf-8-codec-cant-decode-byte-0x96-in-position-35-invalid\n",
    "\n",
    "You might also get a warning, you don't really need to do anything about it, if you're curious why that happened visit here https://stackoverflow.com/questions/24251219/pandas-read-csv-low-memory-and-dtype-options\n",
    "\n",
    "Once you're done try opening the csv file in excel and also try viewing it in jupyter notice the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lOlARJjMpWrl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZohcsCsUpWrm"
   },
   "source": [
    "Q2. Try getting a general overview by picking any 1 of the data frames for all subsequent challenges. You can try with multiple ones totally up to you. Try finding the number of rows and columns, store them as a tuple in df_shape. Also find the number of non - NaN values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TCe3ATvMpWrm",
    "outputId": "aea43803-518c-4630-83bc-fe3c20c309d4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "z7CMHB2KpWrm",
    "outputId": "76679f57-08d1-4ac1-f1ec-dcb20db77afe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 47
    },
    "id": "LW_X9l6lpWrn",
    "outputId": "d8b199dc-3c3b-4ab8-acd4-03d276ab8789"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xSehEiwpWrn"
   },
   "source": [
    "Q3. Use the df_csv and find all the rows where NO2 level is greater than 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 791
    },
    "id": "ygc-9WrspWrn",
    "outputId": "d478e90d-047e-4bf1-8a7e-c45700ed9230"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTJsn8LwpWrn"
   },
   "source": [
    "Q4. In the airdata.csv data frame find all the rows where NO2 level is greater than 15 and SO2 level is less than 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 906
    },
    "id": "uS1F-J1spWrn",
    "outputId": "05bad99c-e98b-41ea-d458-a6958a78fd0f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTpGeB_8pWro"
   },
   "source": [
    "Q5. In the airdata.csv data frame select the column with title stn_code and replace all values which have SAMP inside to np.NaN \n",
    "\n",
    "You're highly encouraged to Google Search and look for ways yourself as that is an essential skill but if you don't find anything you can have a look here - https://stackoverflow.com/questions/29247712/how-to-replace-a-value-in-pandas-with-nan\n",
    "\n",
    "You will need to import numpy and alias it, read up here to learn how to do that - https://www.w3schools.com/python/numpy_getting_started.asp\n",
    "\n",
    "To learn more about NaN values visit here - https://www.askpython.com/python/examples/nan-in-numpy-and-pandas#:~:text=It%20is%20used%20to%20represent,754)%20introduced%20NaN%20in%201985."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-sGHujbpWro"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738
    },
    "id": "LmBWOMbrpWro",
    "outputId": "dd10de7a-7fd9-4630-d975-4d2e32ad0499"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pF22KE1gpWro"
   },
   "source": [
    "Q6. On some inspection it seems the Date column is useless to us as we are not doing any time based analysis and it takes up memory, try looking for ways to remove the column itself. There can be multiple ways to do this and you are highly encouraged to find this yourself however some ways listed here https://stackoverflow.com/questions/13411544/delete-column-from-pandas-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IM5sfn1ppWro"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "id": "nfLOvBcNpWro",
    "outputId": "c1169088-e8f4-40c2-9655-e2854d620d29"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyElPSKPpWrp"
   },
   "source": [
    "Q7. Prof. Sheldon wants to do some analysis but he doesn't know how to remove rows so obviously he turns to an engineer for the grunt work. His evaluation requires the location_monitoring_station to be there and all other rows which have no location_monitoring_station are useless. Go through the data and remove all the rows with no value for the location_monitoring_station\n",
    "\n",
    "Again you're highly encouraged to search for ways youself but if you can't find any don't worry we've got your back - https://stackoverflow.com/questions/13851535/how-to-delete-rows-from-a-pandas-dataframe-based-on-a-conditional-expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDnXTjLvpWrp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738
    },
    "id": "IqLXTToGpWrp",
    "outputId": "2a95814c-5486-403e-c292-7a06b5b7177e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKAEI-7cpWrp"
   },
   "source": [
    "Q8. Penny came along and looked at the type column in the file she didn't scroll down and claimed there are only 2 type of locations residential and industrial. Check if her claims are true or not. Penny even betted against Sheldon that there are going to be more Residential ones, check if she won the Vintage Captain Proton DVD (which she totally wants) from Sheldon's prized collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjUrWl4ppWrp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QdNvqo9hpWrp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOoKB2aupWrp"
   },
   "source": [
    "Q9. Sheldon's favourite number is 73 because \"Its mirror, 37, is the 12th and its mirror, 21, is the product of multiplying 7 and 3 ... and in binary 73 is a palindrome, 1001001, which backwards is 1001001.\" Weird fact right, well you don't really need that turns out Sheldon is in the mood for fun and wants only those entries where the stn_code is a multiple of 73. Beware we haven't really cleaned this column so you might be in for a treat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738
    },
    "id": "84iYuF8IpWrq",
    "outputId": "8d8afbae-f7ca-4feb-ddae-cd12147a6ed9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738
    },
    "id": "Ltza8iIvpWrq",
    "outputId": "38c72157-2413-4477-9658-9cf4d9a0ae49"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bTJUf46LrX_d",
    "outputId": "2d66a6e3-8d7e-4356-caea-d2489d78637f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738
    },
    "id": "vxEtZdDSpWrq",
    "outputId": "18fdabd9-4024-4120-b553-fcf920f25c7a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHFWEHO6pWrq"
   },
   "source": [
    "Q10. Congratulations on making it here, hopefully this is the last question. This time Dr. House broke into Sheldon's lab (he could've asked for permisson but that wouldn't suit his personality would it?). He has a patient with amnesia but due to his fingerprint he has been traced to a couple of people in India, due to lack of access to records he doesn't know which one is he so he wants to check them all. He can either be from Hyderabad, Cuttak or Madurai. Now Dr. House has a hunch (those are true quite often) and he feels he has some rare disease Y which is caused by over exposure to SO2 and NO2. Try to help Dr. House by finding all the places which fit the criteria. \n",
    "High exposure to SO2 means over 25 and high exposure to NO2 means over 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "gTRNQ5ujpWrq",
    "outputId": "b2c0c2b7-96cc-49c2-d633-685e6373490b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sols_PSet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
